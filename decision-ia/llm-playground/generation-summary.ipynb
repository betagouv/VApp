{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import Config, RepositoryEnv\n",
    "from ollama_interaction import generate_ollama_request\n",
    "\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des données sur les modèles\n",
    "Nous importons les modèles servant de base pour VApp. Par défaut, les modèles sont quantifiés en int4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model : mistral-nemo:latest\n",
      "model : mistral-small:latest\n",
      "model : qwen2.5:14b\n",
      "model : qwen2.5:32b\n",
      "model : llama3.2:1b\n",
      "model : llama3.1:latest\n"
     ]
    }
   ],
   "source": [
    "# context option are based on https://github.com/NVIDIA/RULER\n",
    "# If model is not on doc we take the nearest one\n",
    "\n",
    "# best context is based on  Effective length\n",
    "# max context is base on claimed length\n",
    "\n",
    "with open('model-data.json','r') as file:\n",
    "    model_data = json.load(file)\n",
    "\n",
    "for item in list(model_data.keys()):\n",
    "    print('model :',item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(RepositoryEnv('.env'))\n",
    "\n",
    "ollama_api_url = config('OLLAMA_API_URL')\n",
    "ollama_bearer_token = config('OLLAMA_BEARER_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data base de travail\n",
    "Import de la base de données générée dans generation-question.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_question = pd.read_csv(\"hard-database/data_question.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection des données de test\n",
    "Pour le moment, le problème est simplifié en se concentrant sur un modèle à trois questions avec trois réponses simples. Les LLM étant connus pour générer de très bons résumés, nous n'avons pas jugé nécessaire d'aller beaucoup plus loin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revitalisation d'une zone humide\n",
      "[\"Quels aspects de votre projet de revitalisation concernent directement le développement ou l'amélioration des circulations routières et piétonnes ?\"\n",
      " \"Votre project est-il situé dans une commune ou groupement intercommunal avec moins de 10.000 habitants ? Quelle serait la part financière que votre projet pourrait recevoir via cette subvention d'investissement?\"\n",
      " \"Vos travaux touchent-ils à l'amélioration du tourisme local? Si oui, comment le développement prévu pour revitaliser une zone humide est-il lié aux objectifs de stratégie touristique départementale ?\"]\n"
     ]
    }
   ],
   "source": [
    "project_id = 0\n",
    "\n",
    "\n",
    "project_description = data_question['project_description'][project_id]\n",
    "question_list = data_question[['q1','q2','q3']].iloc[project_id].values\n",
    "\n",
    "print(project_description)\n",
    "print(question_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumpy_answer_list = [\n",
    "    \"\"\"La revitalisation de la zone humide inclura des aménagements pour améliorer les circulations piétonnes, notamment à travers des sentiers et des passerelles permettant une meilleure accessibilité pour les visiteurs. Ces aménagements favoriseront également une meilleure gestion de la circulation routière aux abords de la zone, réduisant les risques pour les piétons et encourageant un accès sécurisé aux espaces naturels\"\"\",\n",
    "    \"\"\"Le projet est situé dans une commune comptant moins de 10 000 habitants, ce qui permet de bénéficier d’une aide prioritaire dans le cadre de cette subvention. La subvention d’investissement pourrait ainsi couvrir une part significative des coûts de revitalisation, renforçant les actions locales pour la préservation des écosystèmes et l’attractivité de la commune\"\"\",\n",
    "    \"\"\"La revitalisation de la zone humide s'inscrit dans les objectifs de la stratégie touristique départementale en valorisant les espaces naturels comme attraits pour les visiteurs. Ce projet vise à développer un écotourisme durable, en sensibilisant les visiteurs à la préservation des milieux naturels tout en renforçant l'attractivité locale grâce à des équipements respectueux de l'environnement et des parcours éducatifs pour les familles et les éco-touristes\"\"\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage de la fonction gen_prompt_project_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction disponible sous ./prompt_script/gen_prompt_project_summary.py\n",
    "from prompt_script.gen_prompt_project_summary import gen_prompt_project_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple d'usage\n",
    "Pour générer des résumés plus pertinents, nous avons besoin d'un LLM plus \"intelligent\". Notre choix s'est orienté vers Qwen 2.5-14B, qui représente un bon compromis entre vitesse, performance et intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Revitalisation d'une Zone Humide \n",
      "\n",
      "La revitalisation proposée vise la rénovation écologique, le développement piétonnier et une meilleure gestion de l'espace public dans un quartier humide situé en commune rurale. L'aménagement comprendra des sentiers pédestres sécurisés ainsi que plusieurs passerelles pour faciliter les déplacements tout en préservant la flore locale.\n",
      "\n",
      "Le projet s'inscrit également dans le cadre d'une approche de développement local soutenu par une subvention prioritaire, sans obligation financière supplémentaire. La mise en œuvre des aménagements contribuera à réduire l’impact routier environnant et augmenter la sécurité pour les piétons.\n",
      "\n",
      "### Intérêt Touristique\n",
      "\n",
      "Le projet se connecte directement aux objectifs de développement touristique du département, visant un tourisme durable qui valorise nos espaces naturels. Il intégrera des parcours éducatifs respectueux de l'environnement et renforcira ainsi la notoriété locale en tant que destination écologiquement responsable.\n",
      "\n",
      "Ces améliorations aideront à attirer les visiteurs intéressés par le patrimoine local, tout en fournissant un cadre pédagogique pour sensibiliser au besoin urgent de préserver nos écosystèmes.\n"
     ]
    }
   ],
   "source": [
    "model = \"qwen2.5:14b\"\n",
    "model_options = model_data[model]\n",
    "\n",
    "\n",
    "request_options = {\n",
    "    \"num_ctx\": 16384,\n",
    "    \"num_predict\": 2048\n",
    "}\n",
    "\n",
    "prompt_system, prompt_user = gen_prompt_project_summary(project_description,question_list,answer_list=dumpy_answer_list)\n",
    "\n",
    "response = generate_ollama_request(\n",
    "    prompt_system=prompt_system,\n",
    "    response_format=None,\n",
    "    prompt_user=prompt_user,\n",
    "    ollama_api_url=ollama_api_url,\n",
    "    bearer_token=ollama_bearer_token,\n",
    "    model_options = model_options,  # Default to None\n",
    "    model=model, \n",
    "    request_options= request_options,  # Default to None\n",
    "    seed=0,\n",
    "    )\n",
    "\n",
    "print(response['response'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
