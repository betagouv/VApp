{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import Config, RepositoryEnv\n",
    "from ollama_interaction import embeding_ollama_request,generate_ollama_request\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des données sur les modèles\n",
    "Nous importons les modèles servant de base pour VApp. Par défaut, les modèles sont quantifiés en int4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model : mistral-nemo:latest\n",
      "model : mistral-small:latest\n",
      "model : qwen2.5:14b\n",
      "model : qwen2.5:32b\n",
      "model : llama3.2:1b\n",
      "model : llama3.1:latest\n"
     ]
    }
   ],
   "source": [
    "# context option are based on https://github.com/NVIDIA/RULER\n",
    "# If model is not on doc we take the nearest one\n",
    "\n",
    "# best context is based on  Effective length\n",
    "# max context is base on claimed length\n",
    "\n",
    "with open('model-data.json','r') as file:\n",
    "    model_data = json.load(file)\n",
    "\n",
    "for item in list(model_data.keys()):\n",
    "    print('model :',item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(RepositoryEnv('.env'))\n",
    "\n",
    "ollama_api_url = config('OLLAMA_API_URL')\n",
    "ollama_bearer_token = config('OLLAMA_BEARER_TOKEN')\n",
    "\n",
    "gpu_model = config('OLLAMA_GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data base de travail\n",
    "Import de la base de données générée dans download-data-base-at.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"hard-database/data_at_select_ai.csv\",index_col='id')\n",
    "\n",
    "data = data[(data['token_numb_description']<5000)&(data['token_numb_description']>500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load un échantillion de description de projet\n",
    "with open(\"project-description-sample.json\",'r') as file:\n",
    "    project_descrpition_list = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage de la fonction gen_prompt_aide_scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple d'usage\n",
    "Pour générer le scoring, un petit LLM comme llama3.2:1b semble être suffisant. Des benchmark devront être réalisé avec des modèles plus gros mais moins rapide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction disponible sous ./prompt_script/gen_prompt_aide_scoring.py\n",
    "from prompt_script.gen_prompt_aide_scoring import gen_prompt_aide_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "starting :  Revitalisation d'une zone humide\n",
      "project needed 19.716583061218262min to generate score for 1432 sub with 5 seed\n",
      "averaging 0.826s per sub\n",
      "averaging 0.165s per sub indexed on seed_number\n",
      "-------------------------\n",
      "starting :  Entretient d'un vieux moulin\n",
      "project needed 19.54666873613993min to generate score for 1432 sub with 5 seed\n",
      "averaging 0.819s per sub\n",
      "averaging 0.164s per sub indexed on seed_number\n",
      "-------------------------\n",
      "starting :  Réhabilitation d'une ancienne école en lieu dédié à la santé.\n",
      "project needed 19.704740301767984min to generate score for 1432 sub with 5 seed\n",
      "averaging 0.826s per sub\n",
      "averaging 0.165s per sub indexed on seed_number\n",
      "-------------------------\n",
      "starting :  Voir fiche action PVD /ORT n°21 Après une première phase d’aménagement, la commu\n",
      "project needed 19.741469343503315min to generate score for 1432 sub with 5 seed\n",
      "averaging 0.827s per sub\n",
      "averaging 0.165s per sub indexed on seed_number\n",
      "-------------------------\n",
      "starting :  La commune dispose d'outils numériques qu'il est nécessaire d'optimiser et coord\n",
      "project needed 19.420155469576518min to generate score for 1432 sub with 5 seed\n",
      "averaging 0.814s per sub\n",
      "averaging 0.163s per sub indexed on seed_number\n",
      "-------------------------\n",
      "starting :  Création d’un sentier thématique sur la forêt à Rieutord et sur le patrimoine à \n",
      "project needed 19.567977233727774min to generate score for 1432 sub with 5 seed\n",
      "averaging 0.82s per sub\n",
      "averaging 0.164s per sub indexed on seed_number\n",
      "-------------------------\n",
      "starting :  Je souhaite refaire la voirie communal\n",
      "project needed 19.414119136333465min to generate score for 1432 sub with 5 seed\n",
      "averaging 0.813s per sub\n",
      "averaging 0.163s per sub indexed on seed_number\n",
      "-------------------------\n",
      "starting :  Le projet consiste en l’aménagement d’un terrain communal en cœur de commune, jo\n",
      "project needed 19.859434640407564min to generate score for 1432 sub with 5 seed\n",
      "averaging 0.832s per sub\n",
      "averaging 0.166s per sub indexed on seed_number\n"
     ]
    }
   ],
   "source": [
    "seed_number = 5\n",
    "max_retry = 3\n",
    "row_list = []\n",
    "\n",
    "model = \"llama3.1:latest\"\n",
    "model_options = model_data[model]\n",
    "\n",
    "score_sub_request_options = {\n",
    "    \"num_ctx\": 16384,\n",
    "    \"num_predict\": 2\n",
    "}\n",
    "\n",
    "error_list = []\n",
    "\n",
    "request_options = score_sub_request_options\n",
    "\n",
    "for project_descrpition_key in project_descrpition_list:\n",
    "    project_description = project_descrpition_list[project_descrpition_key]\n",
    "    print('-------------------------')\n",
    "    print('starting : ',project_description[:80])\n",
    "    starting_project_time = time.time()\n",
    "    for i, row in data.iterrows():\n",
    "        # print('-------------------------')\n",
    "        # print(project_description)\n",
    "        # print('---------')\n",
    "        # print('Aide : ',row['name'])\n",
    "        aide_description = row['description_md']\n",
    "        aide_eligibility = row['eligibility_md']\n",
    "        prompt_system,prompt_user = gen_prompt_aide_scoring(aide_description,project_description,max_score=5,min_score=-5)\n",
    "\n",
    "        score_sub = 0\n",
    "        seed = 0\n",
    "        scoring_made = 0\n",
    "        retry = 0\n",
    "\n",
    "        start_requesting_score = time.time()\n",
    "        while scoring_made < seed_number and retry < max_retry:\n",
    "            seed += 1\n",
    "            response = generate_ollama_request(\n",
    "                prompt_system=prompt_system,\n",
    "                response_format=None,\n",
    "                prompt_user=prompt_user,\n",
    "                ollama_api_url=ollama_api_url,\n",
    "                bearer_token=ollama_bearer_token,\n",
    "                model_options = model_options,  # Default to None\n",
    "                request_options= request_options,  # Default to None\n",
    "                seed=seed,\n",
    "                )\n",
    "            if response:\n",
    "                try :\n",
    "                    response_filtred = response['response'].replace(' ','').replace('\\n','')\n",
    "                    score_seed = int(response_filtred)\n",
    "                    if score_seed > 5:\n",
    "                        score_seed =5\n",
    "                    if score_seed < -5:\n",
    "                        score_seed = -5\n",
    "                    score_sub+=score_seed\n",
    "                    retry = 0\n",
    "                    scoring_made+=1\n",
    "                    # print(score_sub)\n",
    "                except Exception as error:\n",
    "                    retry += 1\n",
    "                    error_list.append(response_filtred)\n",
    "                    # print(f\"error : {response['response']}\")\n",
    "        end_requesting_score = time.time()\n",
    "        row['project_description'] = project_description\n",
    "        row['project_score'] = score_sub\n",
    "        row['scoring_made'] = scoring_made\n",
    "        row['scoring_error'] = seed - scoring_made\n",
    "        row['request_time_total'] = end_requesting_score - start_requesting_score\n",
    "        row['request_time_single'] = (end_requesting_score - start_requesting_score)/(seed)\n",
    "        row['gpu'] = gpu_model\n",
    "        # print('score : ',score_sub)\n",
    "        # print('error made : ',seed - scoring_made)\n",
    "        row_list.append(row)\n",
    "    end_project_time = time.time()\n",
    "    print(f\"project needed {(end_project_time - starting_project_time)/60}min to generate score for {len(data)} sub with {seed_number} seed\")\n",
    "    print(f\"averaging {(end_project_time - starting_project_time)/len(data) :.3}s per sub\")\n",
    "    print(f\"averaging {(end_project_time - starting_project_time)/(len(data)*seed_number) :.3}s per sub indexed on seed_number\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_score(project_score:int,scoring_made:int,score_max:int=5,score_min:int=-5)->(float,float):\n",
    "    corrected_project_score = project_score/scoring_made\n",
    "\n",
    "    corrected_normalize_score =(corrected_project_score-score_min)/(score_max-score_min)\n",
    "\n",
    "    return corrected_normalize_score, corrected_project_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slug</th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>name_initial</th>\n",
       "      <th>short_title</th>\n",
       "      <th>financers</th>\n",
       "      <th>financers_full</th>\n",
       "      <th>instructors</th>\n",
       "      <th>instructors_full</th>\n",
       "      <th>programs</th>\n",
       "      <th>...</th>\n",
       "      <th>token_numb_eligibility</th>\n",
       "      <th>project_description</th>\n",
       "      <th>project_score</th>\n",
       "      <th>scoring_made</th>\n",
       "      <th>scoring_error</th>\n",
       "      <th>request_time_total</th>\n",
       "      <th>request_time_single</th>\n",
       "      <th>gpu</th>\n",
       "      <th>corrected_normalize_score</th>\n",
       "      <th>corrected_project_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162955</th>\n",
       "      <td>appel-a-projets-pedagogiques-culture-cheval-an...</td>\n",
       "      <td>/aides/appel-a-projets-pedagogiques-culture-ch...</td>\n",
       "      <td>Développer des projets pédagogiques en lien av...</td>\n",
       "      <td>Appel à projets pédagogiques Culture Cheval – ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Conseil départemental de la Manche']</td>\n",
       "      <td>[{'id': 164, 'name': 'Conseil départemental de...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>444</td>\n",
       "      <td>Revitalisation d'une zone humide</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.044942</td>\n",
       "      <td>0.608988</td>\n",
       "      <td>H100</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162956</th>\n",
       "      <td>appel-a-manifestation-dinteret-pour-loccupatio...</td>\n",
       "      <td>/aides/appel-a-manifestation-dinteret-pour-loc...</td>\n",
       "      <td>Candidater à l'appel à manifestation d’intérêt...</td>\n",
       "      <td>Appel à manifestation d’intérêt pour l’occupat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Conseil régional de Provence-Alpes-Côte d'Az...</td>\n",
       "      <td>[{'id': 93, 'name': \"Conseil régional de Prove...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>1306</td>\n",
       "      <td>Revitalisation d'une zone humide</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.837005</td>\n",
       "      <td>0.167401</td>\n",
       "      <td>H100</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162957</th>\n",
       "      <td>passeurs-dimages-en-bourgogne-franche-comte</td>\n",
       "      <td>/aides/passeurs-dimages-en-bourgogne-franche-c...</td>\n",
       "      <td>Mener des projets d'éducation à l'image sur le...</td>\n",
       "      <td>Passeurs d'images</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Ministère de la Culture']</td>\n",
       "      <td>[{'id': 96, 'name': 'Ministère de la Culture',...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>882</td>\n",
       "      <td>Revitalisation d'une zone humide</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.790148</td>\n",
       "      <td>0.158030</td>\n",
       "      <td>H100</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162965</th>\n",
       "      <td>ecoconception-textile-dhabillement-texhabi</td>\n",
       "      <td>/aides/ecoconception-textile-dhabillement-texh...</td>\n",
       "      <td>Soutenir les projets d’écoconception textile e...</td>\n",
       "      <td>Écoconception textile d'habillement - TEXHABI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ADEME']</td>\n",
       "      <td>[{'id': 22, 'name': 'ADEME', 'logo': 'https://...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Revitalisation d'une zone humide</td>\n",
       "      <td>-3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.789822</td>\n",
       "      <td>0.157964</td>\n",
       "      <td>H100</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162966</th>\n",
       "      <td>aqacia-2024-gerer-les-pollutions-a-lozone-et-s...</td>\n",
       "      <td>/aides/aqacia-2024-gerer-les-pollutions-a-lozo...</td>\n",
       "      <td>Gérer les pollutions à l’ozone et sectorielles</td>\n",
       "      <td>AQACIA 2024 - Gérer les pollutions à l’ozone e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ADEME']</td>\n",
       "      <td>[{'id': 22, 'name': 'ADEME', 'logo': 'https://...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Revitalisation d'une zone humide</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.843217</td>\n",
       "      <td>0.168643</td>\n",
       "      <td>H100</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     slug  \\\n",
       "162955  appel-a-projets-pedagogiques-culture-cheval-an...   \n",
       "162956  appel-a-manifestation-dinteret-pour-loccupatio...   \n",
       "162957        passeurs-dimages-en-bourgogne-franche-comte   \n",
       "162965         ecoconception-textile-dhabillement-texhabi   \n",
       "162966  aqacia-2024-gerer-les-pollutions-a-lozone-et-s...   \n",
       "\n",
       "                                                      url  \\\n",
       "162955  /aides/appel-a-projets-pedagogiques-culture-ch...   \n",
       "162956  /aides/appel-a-manifestation-dinteret-pour-loc...   \n",
       "162957  /aides/passeurs-dimages-en-bourgogne-franche-c...   \n",
       "162965  /aides/ecoconception-textile-dhabillement-texh...   \n",
       "162966  /aides/aqacia-2024-gerer-les-pollutions-a-lozo...   \n",
       "\n",
       "                                                     name  \\\n",
       "162955  Développer des projets pédagogiques en lien av...   \n",
       "162956  Candidater à l'appel à manifestation d’intérêt...   \n",
       "162957  Mener des projets d'éducation à l'image sur le...   \n",
       "162965  Soutenir les projets d’écoconception textile e...   \n",
       "162966     Gérer les pollutions à l’ozone et sectorielles   \n",
       "\n",
       "                                             name_initial short_title  \\\n",
       "162955  Appel à projets pédagogiques Culture Cheval – ...         NaN   \n",
       "162956  Appel à manifestation d’intérêt pour l’occupat...         NaN   \n",
       "162957                                  Passeurs d'images         NaN   \n",
       "162965      Écoconception textile d'habillement - TEXHABI         NaN   \n",
       "162966  AQACIA 2024 - Gérer les pollutions à l’ozone e...         NaN   \n",
       "\n",
       "                                                financers  \\\n",
       "162955             ['Conseil départemental de la Manche']   \n",
       "162956  [\"Conseil régional de Provence-Alpes-Côte d'Az...   \n",
       "162957                        ['Ministère de la Culture']   \n",
       "162965                                          ['ADEME']   \n",
       "162966                                          ['ADEME']   \n",
       "\n",
       "                                           financers_full instructors  \\\n",
       "162955  [{'id': 164, 'name': 'Conseil départemental de...          []   \n",
       "162956  [{'id': 93, 'name': \"Conseil régional de Prove...          []   \n",
       "162957  [{'id': 96, 'name': 'Ministère de la Culture',...          []   \n",
       "162965  [{'id': 22, 'name': 'ADEME', 'logo': 'https://...          []   \n",
       "162966  [{'id': 22, 'name': 'ADEME', 'logo': 'https://...          []   \n",
       "\n",
       "       instructors_full programs  ... token_numb_eligibility  \\\n",
       "162955               []       []  ...                    444   \n",
       "162956               []       []  ...                   1306   \n",
       "162957               []       []  ...                    882   \n",
       "162965               []       []  ...                      0   \n",
       "162966               []       []  ...                      0   \n",
       "\n",
       "                     project_description project_score scoring_made  \\\n",
       "162955  Revitalisation d'une zone humide             3            5   \n",
       "162956  Revitalisation d'une zone humide             2            5   \n",
       "162957  Revitalisation d'une zone humide            16            5   \n",
       "162965  Revitalisation d'une zone humide            -3            5   \n",
       "162966  Revitalisation d'une zone humide             0            5   \n",
       "\n",
       "       scoring_error request_time_total request_time_single   gpu  \\\n",
       "162955             0           3.044942            0.608988  H100   \n",
       "162956             0           0.837005            0.167401  H100   \n",
       "162957             0           0.790148            0.158030  H100   \n",
       "162965             0           0.789822            0.157964  H100   \n",
       "162966             0           0.843217            0.168643  H100   \n",
       "\n",
       "       corrected_normalize_score corrected_project_score  \n",
       "162955                      0.56                     0.6  \n",
       "162956                      0.54                     0.4  \n",
       "162957                      0.82                     3.2  \n",
       "162965                      0.44                    -0.6  \n",
       "162966                      0.50                     0.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_project_score = pd.DataFrame(row_list)\n",
    "\n",
    "corrected_normalize_score, corrected_project_score = normalize_score(data_project_score['project_score'],data_project_score['scoring_made'])\n",
    "\n",
    "data_project_score['corrected_normalize_score'] = corrected_normalize_score\n",
    "data_project_score['corrected_project_score'] = corrected_project_score\n",
    "\n",
    "data_project_score.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_project_score.to_csv(f\"hard-database/data_project_scoring_gpu_{gpu_model}.csv\")\n",
    "data_project_score.to_csv(f\"hard-database/data_project_scoring.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
